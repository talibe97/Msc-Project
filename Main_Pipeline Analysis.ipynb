{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "460ecd2c",
   "metadata": {},
   "source": [
    "# Main Analysis\n",
    "\n",
    "we have all of our modules that we require created and now we want to bring everything together to complete the Analysis, the following will be on FD001, the we will buil all the other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc2bcaf",
   "metadata": {},
   "source": [
    " # Module Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc986673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backend: torch | dataset: FD001\n",
      "Train: train_FD001.txt | Test: test_FD001.txt | RUL: RUL_FD001.txt\n"
     ]
    }
   ],
   "source": [
    "# === Module Importing ===\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"  # optional: reduce MPS memory pressure\n",
    "\n",
    "# Standard libs\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Project modules\n",
    "import data_loader as dl\n",
    "import pre_processing as pp\n",
    "import evaluator as ev\n",
    "import base_model as base\n",
    "import lstm_model as lstm\n",
    "import cnn_model as cnn\n",
    "import cnn_lstm_model as cnnlstm\n",
    "\n",
    "# ---- Paths ----\n",
    "ROOT = Path.cwd()\n",
    "CMAPS = ROOT / \"CMaps\"  # keep correct folder case\n",
    "# ==== Minimal config you tweak next time ====\n",
    "DATASET = \"FD001\"       # <— change this to FD002/FD003/FD004 later\n",
    "SEQ_LEN = 30            # sliding window\n",
    "MAX_RUL = 130           # RUL clipping\n",
    "VAL_SPLIT = 0.30        # val split by unit\n",
    "\n",
    "# Files derived from DATASET (so you edit one line only)\n",
    "TRAIN_PATH = CMAPS / f\"train_{DATASET}.txt\"\n",
    "TEST_PATH  = CMAPS / f\"test_{DATASET}.txt\"\n",
    "RUL_PATH   = CMAPS / f\"RUL_{DATASET}.txt\"\n",
    "\n",
    "# Artifacts folder for this dataset\n",
    "ART_DIR = ROOT / f\"{DATASET} data & artefacts\"\n",
    "ART_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"backend: torch | dataset: {DATASET}\")\n",
    "print(\"Train:\", TRAIN_PATH.name, \"| Test:\", TEST_PATH.name, \"| RUL:\", RUL_PATH.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ceb9e8-6a4a-4570-b943-495b1166b7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- SAFE MODE: force CPU, disable MPS completely ----\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"         # stick with torch backend\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"       # no CUDA anywhere\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"0\"   # don't even try MPS fallback\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"  # (harmless on CPU)\n",
    "\n",
    "# Keep threads modest so laptop stays cool\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"2\"\n",
    "\n",
    "# IMPORTANT: after setting env vars, restart the kernel before any imports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7248cd8f",
   "metadata": {},
   "source": [
    " # Load & Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a91e9da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded.\n",
      "  train_df: (20631, 26)   test_df: (13096, 26)   rul_df: (100, 1)\n",
      "Shape: (20631, 26)\n",
      "\n",
      "Unique engines: 100\n",
      "\n",
      "Missing values:\n",
      " 0\n",
      "\n",
      "Max cycles per engine:\n",
      "count    100.000000\n",
      "mean     206.310000\n",
      "std       46.342749\n",
      "min      128.000000\n",
      "25%      177.000000\n",
      "50%      199.000000\n",
      "75%      229.250000\n",
      "max      362.000000\n",
      "Name: time_in_cycles, dtype: float64\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_number</th>\n",
       "      <th>time_in_cycles</th>\n",
       "      <th>op_setting_1</th>\n",
       "      <th>op_setting_2</th>\n",
       "      <th>op_setting_3</th>\n",
       "      <th>sensor_measurement_1</th>\n",
       "      <th>sensor_measurement_2</th>\n",
       "      <th>sensor_measurement_3</th>\n",
       "      <th>sensor_measurement_4</th>\n",
       "      <th>sensor_measurement_5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_measurement_12</th>\n",
       "      <th>sensor_measurement_13</th>\n",
       "      <th>sensor_measurement_14</th>\n",
       "      <th>sensor_measurement_15</th>\n",
       "      <th>sensor_measurement_16</th>\n",
       "      <th>sensor_measurement_17</th>\n",
       "      <th>sensor_measurement_18</th>\n",
       "      <th>sensor_measurement_19</th>\n",
       "      <th>sensor_measurement_20</th>\n",
       "      <th>sensor_measurement_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.19</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_number  time_in_cycles  op_setting_1  op_setting_2  op_setting_3  \\\n",
       "0            1               1       -0.0007       -0.0004         100.0   \n",
       "1            1               2        0.0019       -0.0003         100.0   \n",
       "2            1               3       -0.0043        0.0003         100.0   \n",
       "3            1               4        0.0007        0.0000         100.0   \n",
       "4            1               5       -0.0019       -0.0002         100.0   \n",
       "\n",
       "   sensor_measurement_1  sensor_measurement_2  sensor_measurement_3  \\\n",
       "0                518.67                641.82               1589.70   \n",
       "1                518.67                642.15               1591.82   \n",
       "2                518.67                642.35               1587.99   \n",
       "3                518.67                642.35               1582.79   \n",
       "4                518.67                642.37               1582.85   \n",
       "\n",
       "   sensor_measurement_4  sensor_measurement_5  ...  sensor_measurement_12  \\\n",
       "0               1400.60                 14.62  ...                 521.66   \n",
       "1               1403.14                 14.62  ...                 522.28   \n",
       "2               1404.20                 14.62  ...                 522.42   \n",
       "3               1401.87                 14.62  ...                 522.86   \n",
       "4               1406.22                 14.62  ...                 522.19   \n",
       "\n",
       "   sensor_measurement_13  sensor_measurement_14  sensor_measurement_15  \\\n",
       "0                2388.02                8138.62                 8.4195   \n",
       "1                2388.07                8131.49                 8.4318   \n",
       "2                2388.03                8133.23                 8.4178   \n",
       "3                2388.08                8133.83                 8.3682   \n",
       "4                2388.04                8133.80                 8.4294   \n",
       "\n",
       "   sensor_measurement_16  sensor_measurement_17  sensor_measurement_18  \\\n",
       "0                   0.03                    392                   2388   \n",
       "1                   0.03                    392                   2388   \n",
       "2                   0.03                    390                   2388   \n",
       "3                   0.03                    392                   2388   \n",
       "4                   0.03                    393                   2388   \n",
       "\n",
       "   sensor_measurement_19  sensor_measurement_20  sensor_measurement_21  \n",
       "0                  100.0                  39.06                23.4190  \n",
       "1                  100.0                  39.00                23.4236  \n",
       "2                  100.0                  38.95                23.3442  \n",
       "3                  100.0                  38.88                23.3739  \n",
       "4                  100.0                  38.90                23.4044  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: FD001\n",
      "Mean cycles to failure: 206.31\n",
      "Standard deviation: 46.34\n",
      "Minimum: 128\n",
      "Maximum: 362\n",
      "After preprocessing (FD001, no new pp funcs):\n",
      "  Train engines : 80\n",
      "  Val engines   : 20\n",
      "  X_train shape : (14241, 30, 15)  y_train: (14241,)\n",
      "  X_val   shape : (3490, 30, 15)  y_val  : (3490,)\n",
      "  X_test  shape : (10196, 30, 15)  y_test : (10196,)\n",
      "  Dropped sensors: ['sensor_measurement_1', 'sensor_measurement_5', 'sensor_measurement_10', 'sensor_measurement_16', 'sensor_measurement_18', 'sensor_measurement_19']\n",
      "Data saved to /Users/TalibeBah_1/Documents/University/Msc Project/Assessment 2 Project Report/Msc-Project/FD001 data & artefacts/fd001_seq30.npz\n"
     ]
    }
   ],
   "source": [
    "# --- Load FD001 ---\n",
    "train_df = dl.load_raw_data(CMAPS / f\"train_{DATASET}.txt\")\n",
    "test_df, rul_df = dl.load_test_data(\n",
    "    CMAPS / f\"test_{DATASET}.txt\",\n",
    "    CMAPS / f\"RUL_{DATASET}.txt\"\n",
    ")\n",
    "\n",
    "print(\"Loaded.\")\n",
    "print(\"  train_df:\", train_df.shape, \"  test_df:\", test_df.shape, \"  rul_df:\", rul_df.shape)\n",
    "assert train_df.shape[1] == 26 and test_df.shape[1] == 26\n",
    "\n",
    "dl.inspect_data(train_df)\n",
    "pp.summarise_engine_lifespans(train_df, dataset_name=DATASET)\n",
    "\n",
    "# ---------------------------\n",
    "# 1) TRAIN: make targets first (no leakage)\n",
    "# ---------------------------\n",
    "train_rul = pp.calculate_rul(train_df, max_rul=MAX_RUL)\n",
    "\n",
    "# ---------------------------\n",
    "# 2) Split by unit BEFORE deciding features/scaling\n",
    "# ---------------------------\n",
    "train_split, val_split = pp.split_by_unit(train_rul, test_size=0.2, random_state=42)\n",
    "\n",
    "# ---------------------------\n",
    "# 3) Decide flat sensors using TRAIN ONLY, then drop same cols from val/test\n",
    "# ---------------------------\n",
    "before_cols = list(train_split.columns)\n",
    "train_split_clean = pp.drop_flat_sensors(train_split.copy())\n",
    "after_cols  = list(train_split_clean.columns)\n",
    "dropped_cols = [c for c in before_cols if c not in after_cols]\n",
    "\n",
    "val_split_clean = val_split.drop(columns=[c for c in dropped_cols if c in val_split.columns]).reset_index(drop=True)\n",
    "test_df_clean   = test_df.drop(columns=[c for c in dropped_cols if c in test_df.columns]).reset_index(drop=True)\n",
    "\n",
    "# ---------------------------\n",
    "# 4) TEST: build true RUL from RUL file, then clip like train\n",
    "# ---------------------------\n",
    "import numpy as np\n",
    "last_cycles = test_df_clean.groupby(\"unit_number\")[\"time_in_cycles\"].max()\n",
    "rul_map = dict(zip(sorted(test_df_clean[\"unit_number\"].unique()), rul_df[\"RUL\"].values))\n",
    "test_df_clean = test_df_clean.copy()\n",
    "test_df_clean[\"RUL\"] = test_df_clean.apply(\n",
    "    lambda r: (last_cycles.loc[r[\"unit_number\"]] - r[\"time_in_cycles\"]) + rul_map[r[\"unit_number\"]],\n",
    "    axis=1\n",
    ")\n",
    "test_df_clean[\"RUL\"] = np.minimum(test_df_clean[\"RUL\"], MAX_RUL)\n",
    "\n",
    "# ---------------------------\n",
    "# 5) Scale sensors with ONE scaler fit on TRAIN ONLY (FD001 = single condition)\n",
    "#    (avoid standardise_per_condition here to prevent re-fitting on val/test)\n",
    "# ---------------------------\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sensor_cols = [c for c in train_split_clean.columns if c.startswith(\"sensor_measurement\")]\n",
    "scaler = StandardScaler().fit(train_split_clean[sensor_cols])\n",
    "\n",
    "train_scaled = train_split_clean.copy()\n",
    "val_scaled   = val_split_clean.copy()\n",
    "test_scaled  = test_df_clean.copy()\n",
    "\n",
    "train_scaled[sensor_cols] = scaler.transform(train_scaled[sensor_cols])\n",
    "val_scaled[sensor_cols]   = scaler.transform(val_scaled[sensor_cols])\n",
    "test_scaled[sensor_cols]  = scaler.transform(test_scaled[sensor_cols])\n",
    "\n",
    "# ---------------------------\n",
    "# 6) Windowing with your helper\n",
    "# ---------------------------\n",
    "X_train, y_train = pp.generate_sliding_windows(train_scaled, seq_len=SEQ_LEN)\n",
    "X_val,   y_val   = pp.generate_sliding_windows(val_scaled,   seq_len=SEQ_LEN)\n",
    "X_test,  y_test  = pp.generate_sliding_windows(test_scaled,  seq_len=SEQ_LEN)\n",
    "\n",
    "print(\"After preprocessing (FD001, no new pp funcs):\")\n",
    "print(\"  Train engines :\", train_scaled['unit_number'].nunique())\n",
    "print(\"  Val engines   :\",   val_scaled['unit_number'].nunique())\n",
    "print(\"  X_train shape :\", X_train.shape, \" y_train:\", y_train.shape)\n",
    "print(\"  X_val   shape :\", X_val.shape,   \" y_val  :\", y_val.shape)\n",
    "print(\"  X_test  shape :\", X_test.shape,  \" y_test :\", y_test.shape)\n",
    "print(\"  Dropped sensors:\", dropped_cols)\n",
    "\n",
    "# --- Save to use in model ---\n",
    "out_npz = ART_DIR / f\"{DATASET.lower()}_seq{SEQ_LEN}.npz\"\n",
    "pp.save_preprocessed_data(X_train, y_train, X_val, y_val, X_test, y_test, filename=str(out_npz))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2561cd",
   "metadata": {},
   "source": [
    " # Train / Save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9eb908",
   "metadata": {},
   "source": [
    " ## Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cea0a0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shapes (base model):\n",
      "  X_train: (14241, 15)  y_train: (14241,)\n",
      "  X_val  : (3490, 15)  y_val  : (3490,)\n",
      "Saved base model to: /Users/TalibeBah_1/Documents/University/Msc Project/Assessment 2 Project Report/Msc-Project/FD001 data & artefacts/models/base_linear_fd001_seq30_last.joblib\n"
     ]
    }
   ],
   "source": [
    "from base_model import train_linear_model\n",
    "\n",
    "# 1) Load cached windows\n",
    "npz_path = ART_DIR / f\"{DATASET.lower()}_seq{SEQ_LEN}.npz\"\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = pp.load_preprocessed_data(str(npz_path))\n",
    "\n",
    "# 2) Convert 3D windows -> 2D feature vectors for baseline\n",
    "#    (stick to your existing helper; default strategy='last')\n",
    "X_train_feat = pp.make_feature_vectors_from_windows(X_train, strategy='last')\n",
    "X_val_feat   = pp.make_feature_vectors_from_windows(X_val,   strategy='last')\n",
    "\n",
    "print(\"Feature shapes (base model):\")\n",
    "print(\"  X_train:\", X_train_feat.shape, \" y_train:\", y_train.shape)\n",
    "print(\"  X_val  :\", X_val_feat.shape,   \" y_val  :\", y_val.shape)\n",
    "\n",
    "# 3) Train simple Linear Regression\n",
    "base_model = train_linear_model(X_train_feat, y_train)\n",
    "\n",
    "# 4) Save the trained model\n",
    "models_dir = ART_DIR / \"models\"\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_path = models_dir / f\"base_linear_{DATASET.lower()}_seq{SEQ_LEN}_last.joblib\"\n",
    "joblib.dump(base_model, model_path)\n",
    "\n",
    "print(\"Saved base model to:\", model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b44af62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Force CPU, avoid MPS quirks (must be first cell, then restart kernel) ---\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"                 # you’re staying on torch backend\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"       # route unsupported ops to CPU\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"  # reduce MPS memory pressure\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"             # tame BLAS threading\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"2\"             # (harmless if MKL not present)\n",
    "\n",
    "import torch\n",
    "torch.set_default_device(\"cpu\")\n",
    "torch.set_num_threads(2)          # avoid thread blowups# hard-force CPU for PyTorch\n",
    "\n",
    "# (If you’re on Keras 3+, also do:)\n",
    "try:\n",
    "    import keras\n",
    "    keras.config.set_device(\"cpu\")                    # Keras-side device pin\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import gc, keras\n",
    "keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8310412f",
   "metadata": {},
   "source": [
    " ## cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a27465b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m  1/112\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 105ms/step - loss: 9763.4551"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/TalibeBah_1/anaconda3/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - loss: 4603.8496 - val_loss: 572.2763\n",
      "Epoch 2/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - loss: 756.4366 - val_loss: 524.9558\n",
      "Epoch 3/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - loss: 696.5880 - val_loss: 493.5305\n",
      "Epoch 4/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - loss: 626.3881 - val_loss: 396.6181\n",
      "Epoch 5/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - loss: 522.4110 - val_loss: 381.4015\n",
      "Epoch 6/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - loss: 492.3187 - val_loss: 364.1037\n",
      "Epoch 7/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - loss: 440.2897 - val_loss: 321.4193\n",
      "Epoch 8/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - loss: 392.3257 - val_loss: 310.8610\n",
      "Epoch 9/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - loss: 336.7038 - val_loss: 325.8358\n",
      "Epoch 10/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - loss: 303.0135 - val_loss: 295.5705\n",
      "Epoch 11/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - loss: 278.1110 - val_loss: 292.6694\n",
      "Epoch 12/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - loss: 256.1712 - val_loss: 301.2495\n",
      "Epoch 13/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - loss: 245.1246 - val_loss: 298.1215\n",
      "Epoch 14/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - loss: 230.2874 - val_loss: 295.1285\n",
      "Epoch 15/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - loss: 217.5275 - val_loss: 323.7522\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Saved CNN model to: /Users/TalibeBah_1/Documents/University/Msc Project/Assessment 2 Project Report/Msc-Project/FD001 data & artefacts/models/cnn_fd001_seq30.keras\n"
     ]
    }
   ],
   "source": [
    "# --- Train / Save: CNN (FD001) ---\n",
    "\n",
    "from cnn_model import build_cnn_model, train_cnn_model\n",
    "import json\n",
    "\n",
    "# 1) Load cached 3D windows\n",
    "npz_path = ART_DIR / f\"{DATASET.lower()}_seq{SEQ_LEN}.npz\"\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = pp.load_preprocessed_data(str(npz_path))\n",
    "\n",
    "# 2) Build CNN\n",
    "input_shape = (SEQ_LEN, X_train.shape[2])\n",
    "cnn = build_cnn_model(input_shape)\n",
    "\n",
    "# 3) Train (only pass what your module expects!)\n",
    "cnn, history = train_cnn_model(cnn, X_train, y_train, X_val, y_val, epochs=30, batch_size=128)\n",
    "\n",
    "# 4) Save model + meta\n",
    "models_dir = ART_DIR / \"models\"\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "model_path = models_dir / f\"cnn_{DATASET.lower()}_seq{SEQ_LEN}.keras\"\n",
    "cnn.save(model_path)\n",
    "\n",
    "meta = {\n",
    "    \"model_type\": \"cnn\",\n",
    "    \"dataset\": DATASET,\n",
    "    \"seq_len\": int(SEQ_LEN),\n",
    "    \"features\": int(X_train.shape[2]),\n",
    "    \"epochs\": 30,\n",
    "    \"batch_size\": 128\n",
    "}\n",
    "with open(models_dir / f\"cnn_{DATASET.lower()}_seq{SEQ_LEN}.meta.json\", \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"Saved CNN model to:\", model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe31aef8",
   "metadata": {},
   "source": [
    " ## lstm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "241985ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/TalibeBah_1/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 126ms/step - loss: 8011.9199 - val_loss: 6838.4185\n",
      "Epoch 2/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 6893.0752 - val_loss: 6295.9658\n",
      "Epoch 3/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 124ms/step - loss: 6303.1367 - val_loss: 5814.4448\n",
      "Epoch 4/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 129ms/step - loss: 5745.1343 - val_loss: 5372.5942\n",
      "Epoch 5/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 135ms/step - loss: 5405.8486 - val_loss: 4967.4497\n",
      "Epoch 6/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 136ms/step - loss: 4953.6924 - val_loss: 4591.7607\n",
      "Epoch 7/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 140ms/step - loss: 4667.8804 - val_loss: 4243.8081\n",
      "Epoch 8/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 136ms/step - loss: 4331.8940 - val_loss: 3921.6006\n",
      "Epoch 9/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 139ms/step - loss: 3917.7300 - val_loss: 3622.7456\n",
      "Epoch 10/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - loss: 3669.1177 - val_loss: 3342.7810\n",
      "Epoch 11/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 142ms/step - loss: 3333.8140 - val_loss: 3084.1123\n",
      "Epoch 12/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 143ms/step - loss: 3157.0928 - val_loss: 2842.2317\n",
      "Epoch 13/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 144ms/step - loss: 2844.9473 - val_loss: 2623.2891\n",
      "Epoch 14/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 146ms/step - loss: 2648.6787 - val_loss: 2412.3406\n",
      "Epoch 15/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 146ms/step - loss: 2462.6755 - val_loss: 2219.8257\n",
      "Epoch 16/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 144ms/step - loss: 2246.4060 - val_loss: 2041.5399\n",
      "Epoch 17/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 146ms/step - loss: 2080.5242 - val_loss: 1880.5145\n",
      "Epoch 18/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 146ms/step - loss: 1918.8264 - val_loss: 1724.5691\n",
      "Epoch 19/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 157ms/step - loss: 1750.9824 - val_loss: 1580.4618\n",
      "Epoch 20/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 157ms/step - loss: 1591.2817 - val_loss: 1452.1593\n",
      "Epoch 21/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 159ms/step - loss: 1471.0740 - val_loss: 1330.8091\n",
      "Epoch 22/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 167ms/step - loss: 1368.9501 - val_loss: 1219.8477\n",
      "Epoch 23/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 169ms/step - loss: 1253.2576 - val_loss: 1118.5891\n",
      "Epoch 24/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 172ms/step - loss: 1155.6205 - val_loss: 1028.7843\n",
      "Epoch 25/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 179ms/step - loss: 1063.6635 - val_loss: 935.6535\n",
      "Epoch 26/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 184ms/step - loss: 997.7189 - val_loss: 865.6830\n",
      "Epoch 27/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 186ms/step - loss: 897.8106 - val_loss: 796.3045\n",
      "Epoch 28/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 197ms/step - loss: 810.7772 - val_loss: 733.2637\n",
      "Epoch 29/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 190ms/step - loss: 764.1095 - val_loss: 659.3265\n",
      "Epoch 30/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 197ms/step - loss: 695.1135 - val_loss: 616.5401\n",
      "Saved LSTM model to: /Users/TalibeBah_1/Documents/University/Msc Project/Assessment 2 Project Report/Msc-Project/FD001 data & artefacts/models/lstm_fd001_seq30.keras\n"
     ]
    }
   ],
   "source": [
    "# --- LSTM model (train + save) ---\n",
    "\n",
    "from lstm_model import build_lstm_model, train_lstm_model\n",
    "import json\n",
    "\n",
    "# 1) Load cached 3D windows\n",
    "npz_path = ART_DIR / f\"{DATASET.lower()}_seq{SEQ_LEN}.npz\"\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = pp.load_preprocessed_data(str(npz_path))\n",
    "\n",
    "# 2) Build LSTM (input: [seq_len, n_features])\n",
    "input_shape = (SEQ_LEN, X_train.shape[2])\n",
    "lstm = build_lstm_model(input_shape)\n",
    "\n",
    "# 3) Train (pass only what your module expects)\n",
    "#    If your train_lstm_model returns (model, history), keep both; if it returns only model, handle that too.\n",
    "result = train_lstm_model(lstm, X_train, y_train, X_val, y_val, epochs=50, batch_size=128)\n",
    "if isinstance(result, tuple):\n",
    "    lstm, lstm_history = result\n",
    "else:\n",
    "    lstm = result\n",
    "    lstm_history = None\n",
    "\n",
    "# 4) Save model + minimal metadata\n",
    "models_dir = ART_DIR / \"models\"\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_path = models_dir / f\"lstm_{DATASET.lower()}_seq{SEQ_LEN}.keras\"\n",
    "lstm.save(model_path)\n",
    "\n",
    "meta = {\n",
    "    \"model_type\": \"lstm\",\n",
    "    \"dataset\": DATASET,\n",
    "    \"seq_len\": int(SEQ_LEN),\n",
    "    \"features\": int(X_train.shape[2]),\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "with open(models_dir / f\"lstm_{DATASET.lower()}_seq{SEQ_LEN}.meta.json\", \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"Saved LSTM model to:\", model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dce09b5-54b5-462e-a11c-26be81b0baab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12118114-46dd-4feb-828f-a96fd437faca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87c4d87d",
   "metadata": {},
   "source": [
    " ## lstm_cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb72d08-75e7-4ee5-903a-d3468e88b4da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaf09d0-e112-4008-899c-d0f57a33e5a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93045888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CNN-LSTM model (train + save) ---\n",
    "\n",
    "from cnn_lstm_model import build_cnn_lstm_model, train_cnn_lstm_model\n",
    "import json\n",
    "\n",
    "# 1) Load cached 3D windows\n",
    "npz_path = ART_DIR / f\"{DATASET.lower()}_seq{SEQ_LEN}.npz\"\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = pp.load_preprocessed_data(str(npz_path))\n",
    "\n",
    "# 2) Build model (input: [seq_len, n_features])\n",
    "input_shape = (SEQ_LEN, X_train.shape[2])\n",
    "cnnlstm = build_cnn_lstm_model(input_shape)\n",
    "\n",
    "# 3) Train (pass only what your module expects)\n",
    "#    Handle both return styles: model OR (model, history)\n",
    "result = train_cnn_lstm_model(cnnlstm, X_train, y_train, X_val, y_val, epochs=40, batch_size=100)\n",
    "if isinstance(result, tuple):\n",
    "    cnnlstm, cnnlstm_history = result\n",
    "else:\n",
    "    cnnlstm = result\n",
    "    cnnlstm_history = None\n",
    "\n",
    "# 4) Save model + minimal metadata\n",
    "models_dir = ART_DIR / \"models\"\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_path = models_dir / f\"cnn_lstm_{DATASET.lower()}_seq{SEQ_LEN}.keras\"\n",
    "cnnlstm.save(model_path)\n",
    "\n",
    "meta = {\n",
    "    \"model_type\": \"cnn_lstm\",\n",
    "    \"dataset\": DATASET,\n",
    "    \"seq_len\": int(SEQ_LEN),\n",
    "    \"features\": int(X_train.shape[2]),\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "with open(models_dir / f\"cnn_lstm_{DATASET.lower()}_seq{SEQ_LEN}.meta.json\", \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"Saved CNN-LSTM model to:\", model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21713f29",
   "metadata": {},
   "source": [
    " # Run Models / Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602fc40a",
   "metadata": {},
   "source": [
    " ## base model / run and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd709853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Linear Model Evaluation:\n",
      "  RMSE: 23.2810\n",
      "  MAE : 18.8226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'Base Linear Model', 'RMSE': 23.280973, 'MAE': 18.8226}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from evaluator import evaluate_model\n",
    "import pre_processing as pp\n",
    "\n",
    "# load preprocessed test set\n",
    "npz_path = ART_DIR / f\"{DATASET.lower()}_seq{SEQ_LEN}.npz\"\n",
    "_, _, _, _, X_test, y_test = pp.load_preprocessed_data(str(npz_path))\n",
    "\n",
    "# convert if using base model (needs 2D vectors)\n",
    "X_test_feat = pp.make_feature_vectors_from_windows(X_test, strategy=\"last\")\n",
    "\n",
    "# load trained base model\n",
    "model_path = ART_DIR / \"models\" / f\"base_linear_{DATASET.lower()}_seq{SEQ_LEN}_last.joblib\"\n",
    "base_model = joblib.load(model_path)\n",
    "\n",
    "# predict & evaluate\n",
    "y_pred = base_model.predict(X_test_feat)\n",
    "evaluate_model(y_test, y_pred, model_name=\"Base Linear Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbea297",
   "metadata": {},
   "source": [
    " ## cnn model / run and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34d8e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Predict & evaluate: CNN on FD001 test ---\n",
    "\n",
    "from keras.models import load_model\n",
    "from evaluator import evaluate_model\n",
    "import pre_processing as pp\n",
    "\n",
    "# 1) Load cached test windows\n",
    "npz_path = ART_DIR / f\"{DATASET.lower()}_seq{SEQ_LEN}.npz\"\n",
    "_, _, _, _, X_test, y_test = pp.load_preprocessed_data(str(npz_path))\n",
    "\n",
    "# 2) Load saved CNN\n",
    "cnn_path = ART_DIR / \"models\" / f\"cnn_{DATASET.lower()}_seq{SEQ_LEN}.keras\"\n",
    "cnn_model = load_model(cnn_path)\n",
    "\n",
    "# 3) Predict (CNN expects 3D windows)\n",
    "y_cnn_pred = cnn_model.predict(X_test, verbose=0).squeeze()\n",
    "\n",
    "# 4) Evaluate\n",
    "evaluate_model(y_test, y_cnn_pred, model_name=\"CNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940374b3",
   "metadata": {},
   "source": [
    " ## lstm model / run and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c069c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Predict & evaluate: LSTM on FD001 test ---\n",
    "\n",
    "from keras.models import load_model\n",
    "from evaluator import evaluate_model\n",
    "import pre_processing as pp\n",
    "\n",
    "# 1) Load cached test windows\n",
    "npz_path = ART_DIR / f\"{DATASET.lower()}_seq{SEQ_LEN}.npz\"\n",
    "_, _, _, _, X_test, y_test = pp.load_preprocessed_data(str(npz_path))\n",
    "\n",
    "# 2) Load saved LSTM\n",
    "lstm_path = ART_DIR / \"models\" / f\"lstm_{DATASET.lower()}_seq{SEQ_LEN}.keras\"\n",
    "lstm_model = load_model(lstm_path)\n",
    "\n",
    "# 3) Predict (LSTM expects 3D input)\n",
    "y_lstm_pred = lstm_model.predict(X_test, verbose=0).squeeze()\n",
    "\n",
    "# 4) Evaluate\n",
    "evaluate_model(y_test, y_lstm_pred, model_name=\"LSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28cb650",
   "metadata": {},
   "source": [
    " ## lstm_cnn model / run and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b093866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Predict & evaluate: CNN-LSTM on FD001 test ---\n",
    "\n",
    "from keras.models import load_model\n",
    "from evaluator import evaluate_model\n",
    "import pre_processing as pp\n",
    "\n",
    "# 1) Load cached test windows\n",
    "npz_path = ART_DIR / f\"{DATASET.lower()}_seq{SEQ_LEN}.npz\"\n",
    "_, _, _, _, X_test, y_test = pp.load_preprocessed_data(str(npz_path))\n",
    "\n",
    "# 2) Load saved CNN-LSTM\n",
    "cnnlstm_path = ART_DIR / \"models\" / f\"cnn_lstm_{DATASET.lower()}_seq{SEQ_LEN}.keras\"\n",
    "cnnlstm_model = load_model(cnnlstm_path)\n",
    "\n",
    "# 3) Predict (expects 3D input)\n",
    "y_cnnlstm_pred = cnnlstm_model.predict(X_test, verbose=0).squeeze()\n",
    "\n",
    "# 4) Evaluate\n",
    "evaluate_model(y_test, y_cnnlstm_pred, model_name=\"CNN-LSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbfff1b",
   "metadata": {},
   "source": [
    " # Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bddd7cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base (Linear) Evaluation:\n",
      "  RMSE: 23.2810\n",
      "  MAE : 18.8226\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base (Linear)</td>\n",
       "      <td>23.280973</td>\n",
       "      <td>18.822599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model       RMSE        MAE\n",
       "0  Base (Linear)  23.280973  18.822599"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved metrics to: /Users/TalibeBah/Documents/University/Msc Project/Assessment 2 Project Report/Msc-Project/FD001 data & artefacts/metrics_fd001_seq30.csv\n"
     ]
    }
   ],
   "source": [
    "# # --- EVALUATE: base / cnn / lstm / cnn_lstm on FD001 test set ---\n",
    "\n",
    "\n",
    "import pre_processing as pp\n",
    "from evaluator import evaluate_model  # uses rmse/mae and returns a dict  \n",
    "\n",
    "# Paths/params you already set earlier\n",
    "npz_path   = ART_DIR / f\"{DATASET.lower()}_seq{SEQ_LEN}.npz\"\n",
    "models_dir = ART_DIR / \"models\"\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) Load test arrays\n",
    "_, _, _, _, X_test, y_test = pp.load_preprocessed_data(str(npz_path))  # \n",
    "\n",
    "results = []\n",
    "\n",
    "# ---------- Base (Linear) ----------\n",
    "try:\n",
    "    base_path = models_dir / f\"base_linear_{DATASET.lower()}_seq{SEQ_LEN}_last.joblib\"\n",
    "    base_model = joblib.load(base_path)\n",
    "    X_test_feat = pp.make_feature_vectors_from_windows(X_test, strategy='last')  # 3D -> 2D  \n",
    "    y_pred_base = base_model.predict(X_test_feat).astype(np.float32).ravel()\n",
    "    results.append(evaluate_model(y_test.ravel(), y_pred_base, model_name=\"Base (Linear)\"))  # \n",
    "except Exception as e:\n",
    "    print(f\"[WARN] Base model evaluation skipped: {e}\")\n",
    "\n",
    "# ---------- CNN ----------\n",
    "try:\n",
    "    cnn_path = models_dir / f\"cnn_{DATASET.lower()}_seq{SEQ_LEN}.keras\"\n",
    "    cnn_model = keras.models.load_model(cnn_path)\n",
    "    y_pred_cnn = cnn_model.predict(X_test, batch_size=16, verbose=0).astype(np.float32).ravel()\n",
    "    results.append(evaluate_model(y_test.ravel(), y_pred_cnn, model_name=\"CNN\"))  # \n",
    "except Exception as e:\n",
    "    print(f\"[WARN] CNN evaluation skipped: {e}\")\n",
    "\n",
    "# ---------- LSTM ----------\n",
    "try:\n",
    "    lstm_path = models_dir / f\"lstm_{DATASET.lower()}_seq{SEQ_LEN}.keras\"\n",
    "    lstm_model = keras.models.load_model(lstm_path)\n",
    "    y_pred_lstm = lstm_model.predict(X_test, batch_size=16, verbose=0).astype(np.float32).ravel()\n",
    "    results.append(evaluate_model(y_test.ravel(), y_pred_lstm, model_name=\"LSTM\"))  # \n",
    "except Exception as e:\n",
    "    print(f\"[WARN] LSTM evaluation skipped: {e}\")\n",
    "\n",
    "# ---------- CNN-LSTM ----------\n",
    "try:\n",
    "    cl_path = models_dir / f\"cnn_lstm_{DATASET.lower()}_seq{SEQ_LEN}.keras\"\n",
    "    cl_model = keras.models.load_model(cl_path)\n",
    "    y_pred_cl = cl_model.predict(X_test, batch_size=16, verbose=0).astype(np.float32).ravel()\n",
    "    results.append(evaluate_model(y_test.ravel(), y_pred_cl, model_name=\"CNN-LSTM\"))  # \n",
    "except Exception as e:\n",
    "    print(f\"[WARN] CNN-LSTM evaluation skipped: {e}\")\n",
    "\n",
    "# 2) Results table\n",
    "metrics_df = pd.DataFrame(results).sort_values(\"RMSE\").reset_index(drop=True)\n",
    "display(metrics_df)\n",
    "\n",
    "# 3) Save for later (dashboard/report)\n",
    "out_csv = ART_DIR / f\"metrics_{DATASET.lower()}_seq{SEQ_LEN}.csv\"\n",
    "metrics_df.to_csv(out_csv, index=False)\n",
    "print(\"Saved metrics to:\", out_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d710bdb",
   "metadata": {},
   "source": [
    " # Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20165977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c38674f",
   "metadata": {},
   "source": [
    "# Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b52b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c6e586",
   "metadata": {},
   "source": [
    "# Notes / Comments\n",
    "\n",
    "checks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
